{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from shapely.ops import Point, LineString\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load((Path.cwd() / 'config.json').open('rb'))\n",
    "export_fp = Path(config['project_directory']) / 'CycleAtlanta'\n",
    "if export_fp.exists() == False:\n",
    "    export_fp.mkdir()\n",
    "    \n",
    "traces_fp = Path(config['project_directory']) / \"CycleAtlanta\"\n",
    "user_data_definitions = json.load(open(Path.cwd()/'user_data_definition.json'))\n",
    "cycleatlanta_data_filepath = Path(config['cycleatlanta'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip and User Data for Subsetting the Trace Data\n",
    "Before importing the trace data, we want to subset the trips dataframe to know which trips to map match.\n",
    "1. Remove loops\n",
    "1. Retain the most prevalent trip pattern\n",
    "1. If only two trip patterns between locations for a user, retain the first one that appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO these steps should be in the cycleatlanta repo\n",
    "with (traces_fp/'users_1.pkl').open('rb') as fh:\n",
    "    users = pickle.load(fh)\n",
    "\n",
    "with (traces_fp/'trips_2.pkl').open('rb') as fh:\n",
    "    trips_df = pickle.load(fh)\n",
    "\n",
    "with (traces_fp/'trips_1.pkl').open('rb') as fh:\n",
    "    trips_df1 = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add trip type, description, avg_speed, total_distance back in\n",
    "trips_df1 = trips_df1[['tripid','trip_type','description','total_distance_ft','avg_speed_mph']]\n",
    "trips_df = trips_df.merge(trips_df1,on='tripid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.set_index('tripid',drop=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20338 initial trips\n"
     ]
    }
   ],
   "source": [
    "initial_trips = trips_df.shape[0]\n",
    "print(initial_trips,'initial trips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Remove loop trips\n",
    "These are trips where the origin is the same as the destination. The impedance calibration process can't account for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This many loops: 3873\n"
     ]
    }
   ],
   "source": [
    "no_loops = trips_df['sort_start_label'] != trips_df['sort_end_label']\n",
    "print('This many loops:',(~no_loops).sum())\n",
    "trips_df = trips_df[no_loops]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Find unique trips\n",
    "Will be labelled with a '-1' in either the start_label or end_label column. These will all be retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This many unique trips without labels: 1434\n"
     ]
    }
   ],
   "source": [
    "label = (trips_df[['sort_start_label','sort_end_label']] != (-1,-1)).all(axis=1)\n",
    "unique_trips = trips_df.loc[~label]\n",
    "print('This many unique trips without labels:',(~label).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Choose the most prevelant trip if the trip is not unique\n",
    "Trip origins and destination were labelled by user using DBSCAN. Values of '-1' indicate that an origin or destination was not near others. For repeat trips between ODs (regardless of direction), each trip was labelled according to its trajectory similarity with other trips using Frechet distance. For instance, two trips going from point A to B with the same trip pattern label are similar in routing. A trip between A and B with a different trip pattern label would indicate that this trip takes a different route from the previous two. Each trip pattern label has a trip pattern prevalence that correpsonde to the total number of trips that follow this pattern.\n",
    "\n",
    "For impedance calibration, we want the most common route between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_trips = trips_df.loc[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userid  sort_start_label  sort_end_label\n",
       "14      0.0               1.0                                       [0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "                          2.0               [0.0, 1.0, 2.0, 0.0, 3.0, 4.0, 5.0, 6.0, 7.0, ...\n",
       "                          3.0                                                      [0.0, 0.0]\n",
       "        1.0               2.0                                                      [0.0, 1.0]\n",
       "        2.0               3.0                                                           [0.0]\n",
       "                                                                  ...                        \n",
       "1723    7.0               8.0                                                           [1.0]\n",
       "                          10.0                                                          [0.0]\n",
       "        10.0              12.0                                                          [0.0]\n",
       "1727    0.0               1.0                                                      [0.0, 1.0]\n",
       "1733    0.0               1.0                                                           [0.0]\n",
       "Name: trip_patterns, Length: 2221, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if there is only one trip for a label pair, trip_patterns is nan and the trip is unique\n",
    "#still nans popping up which tells me our code isn't working (need to return later though)\n",
    "redundant_trips.groupby(['userid','sort_start_label','sort_end_label'])['trip_patterns'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_maxes = redundant_trips.groupby(['userid','sort_start_label','sort_end_label'])['trip_pattern_prevalence'].idxmax()\n",
    "most_prevalent = redundant_trips.loc[grouped_maxes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine unique_trips and most_prevalent_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_trip_set = pd.concat([most_prevalent,unique_trips])\n",
    "\n",
    "# #for ones where it's idx select the first?\n",
    "# isna = grouped_maxes[grouped_maxes.isna()].reset_index()\n",
    "# isna.drop(columns=['trip_pattern_prevalence'],inplace=True)\n",
    "# isna = pd.merge(trips_df,isna,on=['userid','sort_start_label','sort_end_label'])\n",
    "# isna = isna.groupby(['userid','sort_start_label','sort_end_label'])['tripid'].agg(list)\n",
    "# last_few = isna.apply(lambda x: x[0]).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12810 trips were not unique\n"
     ]
    }
   ],
   "source": [
    "#how many trips were not unique\n",
    "print(trips_df.shape[0]-reduced_trip_set.shape[0],'trips were not unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trip set: 20338 Reduced trip set: 3655\n"
     ]
    }
   ],
   "source": [
    "print('Full trip set:',initial_trips,'Reduced trip set:',reduced_trip_set.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Filters (trip type, description, distance, speed, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tripid', 'userid', 'remapped_userid', 'start_X', 'start_Y', 'end_X',\n",
       "       'end_Y', 'start_label', 'end_label', 'sort_start_label',\n",
       "       'sort_end_label', 'reverse_trajectory', 'trip_patterns',\n",
       "       'trip_pattern_prevalence', 'trip_type', 'description',\n",
       "       'total_distance_ft', 'avg_speed_mph'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_trip_set.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trip Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Commute         1463\n",
       "Social           751\n",
       "Exercise         442\n",
       "Errand           275\n",
       "Shopping         190\n",
       "Work-Related     181\n",
       "School           125\n",
       "Other            113\n",
       "Work-related      59\n",
       "other             56\n",
       "Name: trip_type, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_trip_set['trip_type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 removed exercise trips\n"
     ]
    }
   ],
   "source": [
    "remove_type = reduced_trip_set['trip_type'].isin(['Exercise'])\n",
    "print(remove_type.sum(),'removed exercise trips')\n",
    "reduced_trip_set = reduced_trip_set[~remove_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trip Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid\n",
       "32568    24.137112\n",
       "9151     20.275450\n",
       "8796     20.248453\n",
       "11904    19.330386\n",
       "31397    18.740044\n",
       "           ...    \n",
       "7189      0.524510\n",
       "7188      0.513198\n",
       "9056      0.512816\n",
       "8356      0.497441\n",
       "3513      0.489709\n",
       "Name: total_distance_ft, Length: 3213, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(reduced_trip_set['total_distance_ft'] / 5280).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 were too long or short\n"
     ]
    }
   ],
   "source": [
    "lower_end = 1\n",
    "upper_end = 10\n",
    "too_short = reduced_trip_set['total_distance_ft'] / 5280 < lower_end\n",
    "too_long = reduced_trip_set['total_distance_ft'] / 5280 > upper_end\n",
    "print(too_short.sum()+too_long.sum(),'were too long or short')\n",
    "reduced_trip_set = reduced_trip_set[(~too_short) & (~too_long)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trip Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid\n",
       "13715    689.238694\n",
       "13717    687.628536\n",
       "17969     17.688240\n",
       "7867      16.029994\n",
       "379       15.710578\n",
       "            ...    \n",
       "5772       0.000000\n",
       "10587      0.000000\n",
       "10560      0.000000\n",
       "5798            NaN\n",
       "25844           NaN\n",
       "Name: avg_speed_mph, Length: 2991, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_trip_set['avg_speed_mph'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 were too slow or fast\n"
     ]
    }
   ],
   "source": [
    "too_slow = reduced_trip_set['avg_speed_mph'] < 5\n",
    "too_fast = reduced_trip_set['avg_speed_mph'] > 16\n",
    "print(too_slow.sum()+too_fast.sum(),'were too slow or fast')\n",
    "reduced_trip_set = reduced_trip_set[(~too_slow)&(~too_fast)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2765 trips remaining for calibration\n"
     ]
    }
   ],
   "source": [
    "print(reduced_trip_set.shape[0],'trips remaining for calibration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export for Map Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (traces_fp/'trips_3.pkl').open('wb') as fh:\n",
    "    pickle.dump(reduced_trip_set,fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
